import streamlit as st
from domain.entities.ab_tester import ABTester
from domain.entities.variation import Variation
from domain.use_cases.ab_statistical_validator import ABStatisticalValidator 

class ResultsComponent:
    def __init__(self, tester: ABTester, variation: Variation): # Changed signature
        self.tester = tester
        self.variation = variation # Store variation entity

        if not self.tester or not self.variation:
            st.error("As entidades Tester e Variation s√£o obrigat√≥rias para ResultsComponent.")
            self.results = {} # Initialize as empty dict to avoid errors
            return

        # Perform statistical validation internally
        validator = ABStatisticalValidator(variation=self.variation, tester=self.tester)
        self.results = validator.get_statistical_results()

        # Ensure conversion rates are in self.results for _display_confidence_intervals
        # if they are not already added by ABStatisticalValidator
        if 'control_conversion_rate' not in self.results:
            self.results['control_conversion_rate'] = self.variation.conversion_rate_a
        if 'variation_conversion_rate' not in self.results:
            self.results['variation_conversion_rate'] = self.variation.conversion_rate_b

    def _display_main_result(self):
        st.subheader("Resultado Principal")
        p_value = self.results.get("p_value", 1.0)
        
        # N√≠vel de confian√ßa desejado, ex: 95.0
        desired_confidence = self.tester.desired_confidence_level
        
        # N√≠vel de signific√¢ncia (alfa), ex: 0.05 para 95% de confian√ßa
        significance_level = 1.0 - (desired_confidence / 100.0)


        confidence_text = f"{desired_confidence:.1f}%".replace(".0%", "%")

        if p_value < significance_level:
        
            st.success("### üéâ Temos um vencedor!")
            st.write(
                f"Pode comemorar! A **Varia√ß√£o (B)** superou o **Controle (A)** "
                f"com um n√≠vel de confian√ßa de **{confidence_text}**."
            )
            st.caption(
                "Isso significa que a mudan√ßa na Varia√ß√£o (B) tem alta probabilidade de ser a causa "
                f"da melhoria, n√£o sendo apenas uma obra do acaso. (p-valor: {p_value:.4f})"
            )
        else:
            # --- COPY MELHORADO (Resultado N√£o Significante) ---
            st.warning("### ü§î Resultado Inconclusivo")
            st.write(
                f"Ainda n√£o h√° evid√™ncias para declarar a **Varia√ß√£o (B)** como vencedora sobre o **Controle (A)**, "
                f"considerando o n√≠vel de confian√ßa de **{confidence_text}**."
            )
            st.caption(
                "Isso n√£o significa que a Varia√ß√£o (B) √© pior, mas que a diferen√ßa observada n√£o foi "
                f"grande o suficiente para descartarmos a chance de ser um resultado aleat√≥rio."
            )

        with st.expander("Crit√©rio de Decis√£o Estat√≠stica"):
            st.markdown(f"""
            A decis√£o de signific√¢ncia √© baseada na compara√ß√£o entre o **p-valor** do teste e o **n√≠vel de signific√¢ncia (Œ±)**.

            - **N√≠vel de Signific√¢ncia (Œ±):** `{significance_level:.3f}` (calculado como `100% - {confidence_text}`)
            - **P-Valor do Teste:** `{p_value:.4f}`

            A regra de decis√£o √©: se o **p-valor for menor que o n√≠vel de signific√¢ncia (Œ±)**, o resultado √© estatisticamente significante.

            Neste caso, como `{p_value:.4f}` √© **{'menor' if p_value < significance_level else 'maior ou igual a'}** `{significance_level:.3f}`, o resultado foi considerado **{'Significante' if p_value < significance_level else 'Inconclusivo'}**.
            """)
        
        st.write("---") # Separador visual
        
        col1, col2, col3 = st.columns(3)
        col1.metric(
            label="Uplift da Convers√£o",
            value=f"{self.results.get('conversion_rate_uplift', 0):.2%}",
            help="Indica o aumento ou diminui√ß√£o percentual da taxa de convers√£o da Varia√ß√£o (B) em rela√ß√£o ao Controle (A). Esta m√©trica quantifica o impacto direto da altera√ß√£o testada."
        )

        col2.metric(
            label="P-Valor",
            value=f"{p_value:.4f}",
            help="Probabilidade de obter os resultados observados (ou mais extremos) caso a hip√≥tese nula seja verdadeira. Um p-valor baixo (menor que o n√≠vel de signific√¢ncia Œ±) sugere que o resultado observado n√£o √© fruto do acaso."
        )

        col3.metric(
            label="Confian√ßa do Resultado",
            value=f"{(1 - p_value):.2%}",
            help="Representa a probabilidade de que a diferen√ßa observada seja real. Calculada como (1 - p-valor), oferece uma interpreta√ß√£o intuitiva da signific√¢ncia. Uma confian√ßa de 97% corresponde a um p-valor de 0.03."
        )

    def _display_confidence_intervals(self):
        with st.expander("üîç An√°lise de Uplift e Intervalos de Confian√ßa"):
            st.markdown("""
            O **Intervalo de Confian√ßa** estima a faixa prov√°vel para a verdadeira taxa de convers√£o de cada grupo. Se os intervalos **n√£o se sobrep√µem**, √© um forte indicativo de que a diferen√ßa de desempenho √© estatisticamente significante. Uma sobreposi√ß√£o sugere que a diferen√ßa observada pode ser fruto do acaso.
            """)
            
            # ... resto do c√≥digo do m√©todo sem altera√ß√µes ...
            p_a = self.results.get('control_conversion_rate', 0)
            p_b = self.results.get('variation_conversion_rate', 0)
            lower_a = self.results.get('control_lower_bound', 0)
            upper_a = self.results.get('control_upper_bound', 0)
            lower_b = self.results.get('variation_lower_bound', 0)
            upper_b = self.results.get('variation_upper_bound', 0)
            
            col1, col2 = st.columns(2)
            with col1:
                st.markdown(f"**Controle (A): {p_a:.2%}**")
                st.write(f"Intervalo: `{lower_a:.2%}` a `{upper_a:.2%}`")
            with col2:
                st.markdown(f"**Varia√ß√£o (B): {p_b:.2%}**")
                st.write(f"Intervalo: `{lower_b:.2%}` a `{upper_b:.2%}`")


    def _display_temporal_and_planning_analysis(self):
        """
        Exibe a an√°lise temporal com um visual aprimorado usando barras de progresso.
        """
        with st.expander("üóìÔ∏è An√°lise Temporal e Planejamento do Teste", expanded=True): # Deixei expandido por padr√£o
            st.markdown("""
            Esta se√ß√£o contextualiza o teste no tempo e compara a dura√ß√£o atual com o planejamento necess√°rio para alcan√ßar poder estat√≠stico, ajudando a decidir quando parar o teste com seguran√ßa.
            """)

            temporal_results = self.results.get("temporal_validation_results", {})
            planning_results = self.results.get("planning_results", {})
            dias_corridos = temporal_results.get('total_duration_days', 0)

            col1, col2 = st.columns(2)

            with col1:
                st.subheader("Situa√ß√£o Atual")
                st.metric("Dura√ß√£o do Teste (Dias)", f"{dias_corridos}")
                st.metric("Dura√ß√£o (Dias √öteis)", f"{temporal_results.get('business_days_duration', 0)}")
                st.metric("M√©dia de Visitantes/Dia", f"{int(temporal_results.get('average_daily_visitors', 0))}")

            with col2:
                st.subheader("Progresso para Conclus√£o")

                # --- Cart√£o para 80% de Poder ---
                with st.container(border=True):
                    dias_necessarios_80 = planning_results.get('required_days_80_power', 0)
                    st.markdown("##### Para 80% de Poder Estat√≠stico")

                    if dias_necessarios_80 > 0:
                        progresso_80 = min(1.0, dias_corridos / dias_necessarios_80)
                        st.progress(progresso_80)
                        st.caption(f"{dias_corridos} de {dias_necessarios_80} dias conclu√≠dos.")
                    else:
                        st.caption("N√£o foi poss√≠vel calcular a dura√ß√£o necess√°ria.")

                    # Status final
                    if dias_corridos >= dias_necessarios_80 and dias_necessarios_80 > 0:
                        st.success("‚úÖ **CONCLU√çDO:** A dura√ß√£o para 80% de poder foi atingida.")
                    else:
                        dias_faltantes_80 = max(0, dias_necessarios_80 - dias_corridos)
                        st.info(f"‚è≥ **Em andamento:** Faltam {dias_faltantes_80} dias para atingir a meta.")
                
                st.write("") # Adiciona um pequeno espa√ßo vertical

                # --- Cart√£o para 95% de Poder ---
                with st.container(border=True):
                    dias_necessarios_95 = planning_results.get('required_days_95_power', 0)
                    st.markdown("##### Para 95% de Poder Estat√≠stico")

                    if dias_necessarios_95 > 0:
                        progresso_95 = min(1.0, dias_corridos / dias_necessarios_95)
                        st.progress(progresso_95)
                        st.caption(f"{dias_corridos} de {dias_necessarios_95} dias conclu√≠dos.")
                    else:
                        st.caption("N√£o foi poss√≠vel calcular a dura√ß√£o necess√°ria.")

                    # Status final
                    if dias_corridos >= dias_necessarios_95 and dias_necessarios_95 > 0:
                        st.success("‚úÖ **CONCLU√çDO:** A dura√ß√£o para 95% de poder foi atingida.")
                    else:
                        dias_faltantes_95 = max(0, dias_necessarios_95 - dias_corridos)
                        st.info(f"‚è≥ **Em andamento:** Faltam {dias_faltantes_95} dias para atingir a meta.")


    def _display_test_validity(self):
        with st.expander("‚úÖ An√°lise de Validade e Poder do Teste"):
            st.markdown("""
            Esta se√ß√£o verifica se os resultados do seu teste s√£o confi√°veis. Verificamos o **Poder Estat√≠stico** (a capacidade de detectar um efeito real) e o **SRM** (se o tr√°fego foi dividido corretamente).
            """)

            # Poder do Teste Observado
            power = self.results.get("observed_test_power", 0)
            st.subheader("Poder do Teste Observado")
            if isinstance(power, (float, int)):
                st.progress(int(power * 100))
                st.write(f"O poder observado do seu teste foi de **{power:.2%}**.")
                if power >= 0.8:
                    st.success("**Excelente!** Seu teste teve uma alta probabilidade de detectar uma diferen√ßa real, caso ela exista.")
                else:
                    st.warning("**Aten√ß√£o!** O poder do teste foi baixo. Isso significa que, mesmo que houvesse uma diferen√ßa real, o teste tinha uma baixa probabilidade de detect√°-la. Para testes futuros, considere aumentar o n√∫mero de visitantes.")
            else:
                st.write("Poder do teste n√£o p√¥de ser calculado.")
            
            st.divider()

            # Valida√ß√£o de SRM
            srm_results = self.results.get("srm_results", {})
            has_srm = srm_results.get("has_srm", False)
            srm_p_value = srm_results.get("srm_p_value", 1.0)
            st.subheader("SRM (Sample Ratio Mismatch)")
            if not has_srm:
                st.success(f"**N√ÉO H√Å SRM.** (P-valor do SRM: {srm_p_value:.3f})")
                st.write("A divis√£o de tr√°fego entre os grupos parece correta. Os resultados do teste s√£o confi√°veis nesse quesito.")
            else:
                st.error(f"**ALERTA DE SRM!** (P-valor do SRM: {srm_p_value:.3f})")
                st.write("A propor√ß√£o de visitantes entre os grupos Controle e Varia√ß√£o √© inesperadamente diferente. Isso pode indicar um problema na configura√ß√£o do teste e invalida os resultados. Verifique sua ferramenta de A/B testing.")

    def render(self):
        if not self.results: # Check if results were properly initialized
            st.error("N√£o foi poss√≠vel gerar o relat√≥rio de resultados. Verifique os dados de entrada.")
            return
            
        st.title("üìä Relat√≥rio de Resultados")
        self._display_main_result()
        st.divider()
        self._display_confidence_intervals()
        self._display_test_validity()
        self._display_temporal_and_planning_analysis()
        st.write("---")