import pandas as pd
import streamlit as st
import textwrap
from domain.entities.ab_tester import ABTester
from domain.entities.variation import Variation
from domain.use_cases.ab_statistical_validator import ABStatisticalValidator 

class ResultsComponent:
    def __init__(self, tester: ABTester, variation: Variation): # Changed signature
        self.tester = tester
        self.variation = variation # Store variation entity

        if not self.tester or not self.variation:
            st.error("As entidades Tester e Variation s√£o obrigat√≥rias para ResultsComponent.")
            self.results = {} # Initialize as empty dict to avoid errors
            return

        # Perform statistical validation internally
        validator = ABStatisticalValidator(variation=self.variation, tester=self.tester)
        self.results = validator.get_statistical_results()

        # Ensure conversion rates are in self.results for _display_confidence_intervals
        # if they are not already added by ABStatisticalValidator
        if 'control_conversion_rate' not in self.results:
            self.results['control_conversion_rate'] = self.variation.conversion_rate_a
        if 'variation_conversion_rate' not in self.results:
            self.results['variation_conversion_rate'] = self.variation.conversion_rate_b

    def _apply_custom_css(self):
            """Aplica CSS customizado para corrigir a largura dos tooltips."""
            st.markdown("""
            <style>
            /* Alvo espec√≠fico do container do conte√∫do do tooltip do Streamlit */
            div[data-testid="stTooltipContent"] {
                max-width: 1000px !important;  /* Aumenta a largura E for√ßa a aplica√ß√£o da regra */
                word-wrap: break-word;
                white-space: normal;
            }
            </style>
            """, unsafe_allow_html=True)

    def _display_main_result(self):
        st.subheader("Resultado Principal")
        p_value = self.results.get("p_value", 1.0)
        
        # N√≠vel de confian√ßa desejado, ex: 95.0
        desired_confidence = self.tester.desired_confidence_level
        
        # N√≠vel de signific√¢ncia (alfa), ex: 0.05 para 95% de confian√ßa
        significance_level = 1.0 - (desired_confidence / 100.0)


        confidence_text = f"{desired_confidence:.1f}%".replace(".0%", "%")

        if p_value < significance_level:
        
            st.success("### üéâ Temos um vencedor!")
            st.write(
                f"Pode comemorar! A **Varia√ß√£o (B)** superou o **Controle (A)** "
                f"com um n√≠vel de confian√ßa de **{confidence_text}**."
            )
            st.caption(
                "Isso significa que a mudan√ßa na Varia√ß√£o (B) tem alta probabilidade de ser a causa "
                f"da melhoria, n√£o sendo apenas uma obra do acaso. (p-valor: {p_value:.4f})"
            )
        else:
            # --- COPY MELHORADO (Resultado N√£o Significante) ---
            st.warning("### ü§î Resultado Inconclusivo")
            st.write(
                f"Ainda n√£o h√° evid√™ncias para declarar a **Varia√ß√£o (B)** como vencedora sobre o **Controle (A)**, "
                f"considerando o n√≠vel de confian√ßa de **{confidence_text}**."
            )
            st.caption(
                "Isso n√£o significa que a Varia√ß√£o (B) √© pior, mas que a diferen√ßa observada n√£o foi "
                f"grande o suficiente para descartarmos a chance de ser um resultado aleat√≥rio."
            )

        with st.expander("Crit√©rio de Decis√£o Estat√≠stica"):
            st.markdown(f"""
            A decis√£o de signific√¢ncia √© baseada na compara√ß√£o entre o **p-valor** do teste e o **n√≠vel de signific√¢ncia (Œ±)**.

            - **N√≠vel de Signific√¢ncia (Œ±):** `{significance_level:.3f}` (calculado como `100% - {confidence_text}`)
            - **P-Valor do Teste:** `{p_value:.4f}`

            A regra de decis√£o √©: se o **p-valor for menor que o n√≠vel de signific√¢ncia (Œ±)**, o resultado √© estatisticamente significante.

            Neste caso, como `{p_value:.4f}` √© **{'menor' if p_value < significance_level else 'maior ou igual a'}** `{significance_level:.3f}`, o resultado foi considerado **{'Significante' if p_value < significance_level else 'Inconclusivo'}**.
            """)
        
        st.write("---") # Separador visual
        
        col1, col2, col3 = st.columns(3)
        col1.metric(
            label="Uplift da Convers√£o",
            value=f"{self.results.get('conversion_rate_uplift', 0):.2%}",
            help="Indica o aumento ou diminui√ß√£o percentual da taxa de convers√£o da Varia√ß√£o (B) em rela√ß√£o ao Controle (A). Esta m√©trica quantifica o impacto direto da altera√ß√£o testada."
        )

        col2.metric(
            label="P-Valor",
            value=f"{p_value:.4f}",
            help="Probabilidade de obter os resultados observados (ou mais extremos) caso a hip√≥tese nula seja verdadeira. Um p-valor baixo (menor que o n√≠vel de signific√¢ncia Œ±) sugere que o resultado observado n√£o √© fruto do acaso."
        )

        col3.metric(
            label="Confian√ßa do Resultado",
            value=f"{(1 - p_value):.2%}",
            help="Representa a probabilidade de que a diferen√ßa observada seja real. Calculada como (1 - p-valor), oferece uma interpreta√ß√£o intuitiva da signific√¢ncia. Uma confian√ßa de 97% corresponde a um p-valor de 0.03."
        )

    def _display_confidence_intervals(self):
        """
        Exibe a an√°lise de signific√¢ncia estat√≠stica com uma interface clara e conclus√µes diretas.
        """
        with st.expander("üí° An√°lise de Signific√¢ncia Estat√≠stica e Uplift", expanded=True):
            st.markdown("""
            Para garantir que a diferen√ßa de convers√£o n√£o √© fruto do acaso, analisamos os **Intervalos de Confian√ßa**.
            Pense neles como a "margem de erro" de cada vers√£o. Eles nos mostram a faixa onde a verdadeira taxa de convers√£o provavelmente se encontra.
            """)

            p_a = self.results.get('control_conversion_rate', 0)
            p_b = self.results.get('variation_conversion_rate', 0)
            lower_a = self.results.get('control_lower_bound', 0)
            upper_a = self.results.get('control_upper_bound', 0)
            lower_b = self.results.get('variation_lower_bound', 0)
            upper_b = self.results.get('variation_upper_bound', 0)
            
            # --- NOVO: L√≥gica para verificar a sobreposi√ß√£o ---
            # A sobreposi√ß√£o ocorre se o limite inferior de um grupo for menor que o limite superior do outro.
            # Verificamos a condi√ß√£o de N√ÉO sobreposi√ß√£o para simplificar.
            no_overlap = (upper_a < lower_b) or (upper_b < lower_a)
            
            st.divider() # Adiciona uma linha visual

            # --- NOVO: Mensagem de conclus√£o baseada na sobreposi√ß√£o ---
            if no_overlap:
                st.success(
                    "**‚úÖ Resultado Significativo: Os intervalos de confian√ßa N√ÉO se sobrep√µem.**\n\n"
                    "H√° uma forte evid√™ncia estat√≠stica de que a diferen√ßa entre os grupos √© real."
                )
            else:
                st.warning(
                    "**‚ö†Ô∏è Resultado Inconclusivo: Os intervalos de confian√ßa se sobrep√µem.**\n\n"
                    "N√£o h√° evid√™ncia estat√≠stica para afirmar que uma vers√£o √© superior √† outra."
                )

            st.divider()

            # --- NOVO: Layout em colunas com st.metric ---
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("**Controle (A)**")
                st.metric(label="Taxa de Convers√£o", value=f"{p_a:.2%}")
                st.markdown(f"**Intervalo de Confian√ßa (95%):** `{lower_a:.2%}` ‚Äî `{upper_a:.2%}`")
                
            with col2:
                st.markdown("**Varia√ß√£o (B)**")
                st.metric(label="Taxa de Convers√£o", value=f"{p_b:.2%}")
                st.markdown(f"**Intervalo de Confian√ßa (95%):** `{lower_b:.2%}` ‚Äî `{upper_b:.2%}`")

            st.caption("Nota T√©cnica: Um n√≠vel de confian√ßa de 95% indica que, se repet√≠ssemos o teste 100 vezes, em 95 delas a taxa de convers√£o real estaria dentro do intervalo.")


    def _display_temporal_and_planning_analysis(self):
        """
        Exibe a an√°lise temporal com um visual aprimorado usando barras de progresso.
        """
        with st.expander("üóìÔ∏è An√°lise Temporal e Planejamento do Teste", expanded=True): # Deixei expandido por padr√£o
            st.markdown("""
            Esta se√ß√£o contextualiza o teste no tempo e compara a dura√ß√£o atual com o planejamento necess√°rio para alcan√ßar poder estat√≠stico, ajudando a decidir quando parar o teste com seguran√ßa.
            """)

            temporal_results = self.results.get("temporal_validation_results", {})
            planning_results = self.results.get("planning_results", {})
            dias_corridos = temporal_results.get('total_duration_days', 0)

            col1, col2 = st.columns(2)

            with col1:
                st.subheader("Situa√ß√£o Atual")
                st.metric("Dura√ß√£o do Teste (Dias)", f"{dias_corridos}")
                st.metric("Dura√ß√£o (Dias √öteis)", f"{temporal_results.get('business_days_duration', 0)}")
                st.metric("M√©dia de Visitantes/Dia", f"{int(temporal_results.get('average_daily_visitors', 0))}")

            with col2:
                st.subheader("Progresso para Conclus√£o")

                # --- Cart√£o para 80% de Poder ---
                with st.container(border=True):
                    dias_necessarios_80 = planning_results.get('required_days_80_power', 0)
                    st.markdown("##### Para 80% de Poder Estat√≠stico")

                    if dias_necessarios_80 > 0:
                        progresso_80 = min(1.0, dias_corridos / dias_necessarios_80)
                        st.progress(progresso_80)
                        st.caption(f"{dias_corridos} de {dias_necessarios_80} dias conclu√≠dos.")
                    else:
                        st.caption("N√£o foi poss√≠vel calcular a dura√ß√£o necess√°ria.")

                    # Status final
                    if dias_corridos >= dias_necessarios_80 and dias_necessarios_80 > 0:
                        st.success("‚úÖ **CONCLU√çDO:** A dura√ß√£o para 80% de poder foi atingida.")
                    else:
                        dias_faltantes_80 = max(0, dias_necessarios_80 - dias_corridos)
                        st.info(f"‚è≥ **Em andamento:** Faltam {dias_faltantes_80} dias para atingir a meta.")
                
                st.write("") # Adiciona um pequeno espa√ßo vertical

                # --- Cart√£o para 95% de Poder ---
                with st.container(border=True):
                    dias_necessarios_95 = planning_results.get('required_days_95_power', 0)
                    st.markdown("##### Para 95% de Poder Estat√≠stico")

                    if dias_necessarios_95 > 0:
                        progresso_95 = min(1.0, dias_corridos / dias_necessarios_95)
                        st.progress(progresso_95)
                        st.caption(f"{dias_corridos} de {dias_necessarios_95} dias conclu√≠dos.")
                    else:
                        st.caption("N√£o foi poss√≠vel calcular a dura√ß√£o necess√°ria.")

                    # Status final
                    if dias_corridos >= dias_necessarios_95 and dias_necessarios_95 > 0:
                        st.success("‚úÖ **CONCLU√çDO:** A dura√ß√£o para 95% de poder foi atingida.")
                    else:
                        dias_faltantes_95 = max(0, dias_necessarios_95 - dias_corridos)
                        st.info(f"‚è≥ **Em andamento:** Faltam {dias_faltantes_95} dias para atingir a meta.")


    def _display_test_validity(self):
        with st.expander("‚úÖ An√°lise de Validade e Poder do Teste"):
            st.markdown("""
            Esta se√ß√£o verifica se os resultados do seu teste s√£o confi√°veis. Verificamos o **Poder Estat√≠stico** (a capacidade de detectar um efeito real) e o **SRM** (se o tr√°fego foi dividido corretamente).
            """)

            # Poder do Teste Observado
            power = self.results.get("observed_test_power", 0)
            st.subheader("Poder do Teste Observado", help=textwrap.dedent("""
            Pense no Poder Estat√≠stico como o 'poder de resolu√ß√£o' do seu teste. Ele quantifica a 
            capacidade do experimento de 'enxergar' uma diferen√ßa real entre as varia√ß√µes, caso ela exista.
            
            Tecnicamente, √© a probabilidade de rejeitar corretamente a hip√≥tese nula quando 
            ela √©, de fato, falsa.

            Sua import√¢ncia √© cr√≠tica para evitar o Erro Tipo II (falso negativo). Um teste com 
            baixo poder pode levar a uma conclus√£o perigosa: abandonar uma ideia vencedora por achar 
            que 'n√£o houve diferen√ßa', quando na verdade o teste apenas n√£o teve 'for√ßa' para detect√°-la.
            
            O padr√£o de 80% de poder garante que voc√™ tenha uma alta probabilidade de confirmar 
            cientificamente as suas hip√≥teses bem-sucedidas.
            """))
            st.markdown("""
                        >O padr√£o de 80% de poder garante que voc√™ tenha uma alta probabilidade de confirmar 
                        cientificamente as suas hip√≥teses bem-sucedidas.
            """)
            if isinstance(power, (float, int)):
                st.progress(int(power * 100))
                st.write(f"O poder observado do seu teste foi de **{power:.2%}**.")
                if power >= 0.8:
                    st.success("**Excelente!** Seu teste teve uma alta probabilidade de detectar uma diferen√ßa real, caso ela exista.")
                else:
                    st.warning("**Aten√ß√£o!** O poder do teste foi baixo. Isso significa que, mesmo que houvesse uma diferen√ßa real, o teste tinha uma baixa probabilidade de detect√°-la. Para testes futuros, considere aumentar o n√∫mero de visitantes.")
            else:
                st.write("Poder do teste n√£o p√¥de ser calculado.")
            
            st.divider()

            # Valida√ß√£o de SRM
            srm_results = self.results.get("srm_results", {})
            has_srm = srm_results.get("has_srm", False)
            srm_p_value = srm_results.get("srm_p_value", 1.0)
            st.subheader("SRM (Sample Ratio Mismatch)", help=textwrap.dedent("""
            O SRM (Sample Ratio Mismatch) verifica se a propor√ß√£o de visitantes entre os grupos Controle e Varia√ß√£o est√° correta. 
            """))      
            if not has_srm:
                st.success(f"**N√ÉO H√Å SRM.** (P-valor do SRM: {srm_p_value:.3f})")
                st.write("A divis√£o de tr√°fego entre os grupos parece correta. Os resultados do teste s√£o confi√°veis nesse quesito.")
            else:
                st.error(f"**ALERTA DE SRM!** (P-valor do SRM: {srm_p_value:.3f})")
                st.write("A propor√ß√£o de visitantes entre os grupos Controle e Varia√ß√£o √© inesperadamente diferente. Isso pode indicar um problema na configura√ß√£o do teste e invalida os resultados. Verifique sua ferramenta de A/B testing.")



    def _display_full_results_table(self):
        """
        Exibe uma tabela completa com TODAS as m√©tricas calculadas (incluindo
        as aninhadas), seus valores e descri√ß√µes.
        """
        with st.expander("üìñ Gloss√°rio de M√©tricas e Resultados Detalhados"):
            
            # Lista de dicion√°rios para definir cada m√©trica, sua descri√ß√£o e formata√ß√£o.
            # A chave 'path' √© uma tupla que indica o caminho para o valor no dicion√°rio de resultados.
            metrics_glossary = [
                # --- Resultados Principais ---
                {'label': 'Uplift da Convers√£o', 'path': ('conversion_rate_uplift',), 'description': 'A melhoria percentual da Varia√ß√£o (B) em rela√ß√£o ao Controle (A).', 'formatter': lambda x: f"{x:.2%}"},
                {'label': 'P-Valor', 'path': ('p_value',), 'description': 'Probabilidade do resultado ser aleat√≥rio. Um valor baixo (< 0.05) indica signific√¢ncia estat√≠stica.', 'formatter': lambda x: f"{x:.4f}"},
                {'label': 'Confian√ßa do Resultado', 'path': ('current_confidence',), 'description': 'Certeza de que a diferen√ßa observada √© real (calculada como 1 - P-Valor).', 'formatter': lambda x: f"{x:.2%}"},
                
                # --- Validade do Teste ---
                {'label': 'Poder do Teste Observado', 'path': ('observed_test_power',), 'description': 'Probabilidade de detectar um efeito real, caso ele exista. Idealmente > 80%.', 'formatter': lambda x: f"{x:.2%}"},
                {'label': 'SRM (Sample Ratio Mismatch)', 'path': ('srm_results', 'has_srm'), 'description': 'Indica se a divis√£o de tr√°fego foi desigual, o que pode invalidar o teste.', 'formatter': lambda x: "Sim" if x else "N√£o"},
                
                # --- An√°lise Temporal (Situa√ß√£o Atual) ---
                {'label': 'Dura√ß√£o Atual (Dias)', 'path': ('temporal_validation_results', 'total_duration_days'), 'description': 'N√∫mero de dias corridos que o teste est√° ativo.', 'formatter': lambda x: f"{int(x)}"},
                {'label': 'Dura√ß√£o Atual (Dias √öteis)', 'path': ('temporal_validation_results', 'business_days_duration'), 'description': 'N√∫mero de dias √∫teis (Seg-Sex) que o teste est√° ativo.', 'formatter': lambda x: f"{int(x)}"},
                {'label': 'M√©dia de Visitantes por Dia', 'path': ('temporal_validation_results', 'average_daily_visitors'), 'description': 'M√©dia de visitantes di√°rios totais (Controle + Varia√ß√£o).', 'formatter': lambda x: f"{int(x)}"},

                # --- Planejamento do Teste ---
                {'label': 'Usu√°rios Necess√°rios (80% Poder)', 'path': ('planning_results', 'required_users_80_power'), 'description': 'Amostra total necess√°ria para atingir 80% de poder estat√≠stico.', 'formatter': lambda x: f"{int(x):,}"},
                {'label': 'Dias Necess√°rios (80% Poder)', 'path': ('planning_results', 'required_days_80_power'), 'description': 'Estimativa de dias para atingir 80% de poder com o tr√°fego atual.', 'formatter': lambda x: f"{int(x)}"},
                {'label': 'Usu√°rios Necess√°rios (95% Poder)', 'path': ('planning_results', 'required_users_95_power'), 'description': 'Amostra total necess√°ria para atingir 95% de poder estat√≠stico.', 'formatter': lambda x: f"{int(x):,}"},
                {'label': 'Dias Necess√°rios (95% Poder)', 'path': ('planning_results', 'required_days_95_power'), 'description': 'Estimativa de dias para atingir 95% de poder com o tr√°fego atual.', 'formatter': lambda x: f"{int(x)}"},

                # --- Detalhes Estat√≠sticos ---
                {'label': 'Z-Score', 'path': ('z_score',), 'description': 'Mede a diferen√ßa entre os grupos em unidades de desvio padr√£o.', 'formatter': lambda x: f"{x:.4f}"},
                {'label': 'Z-Cr√≠tico', 'path': ('z_critical',), 'description': 'Valor de refer√™ncia para o Z-Score baseado no n√≠vel de confian√ßa.', 'formatter': lambda x: f"{x:.4f}"},
                {'label': 'Erro Padr√£o da Diferen√ßa', 'path': ('standard_error_difference',), 'description': 'O desvio padr√£o da diferen√ßa entre as taxas de convers√£o.', 'formatter': lambda x: f"{x:.6f}"},
                {'label': 'Intervalo Confian√ßa - Controle', 'path': ('control_lower_bound',), 'description': 'Faixa prov√°vel da verdadeira taxa de convers√£o do Controle.', 'formatter': lambda x, u=self.results.get('control_upper_bound', 0): f"{x:.2%} - {u:.2%}"},
                {'label': 'Intervalo Confian√ßa - Varia√ß√£o', 'path': ('variation_lower_bound',), 'description': 'Faixa prov√°vel da verdadeira taxa de convers√£o da Varia√ß√£o.', 'formatter': lambda x, u=self.results.get('variation_upper_bound', 0): f"{x:.2%} - {u:.2%}"},
            ]
            
            table_data = []
            # Loop para processar e formatar os dados para a tabela
            for metric_info in metrics_glossary:
                value = self.results
                try:
                    # Navega pelo caminho para encontrar o valor aninhado
                    for key in metric_info['path']:
                        value = value[key]
                    
                    # Formata√ß√£o especial para os intervalos de confian√ßa
                    if 'Intervalo Confian√ßa' in metric_info['label']:
                        # O valor j√° √© formatado com o limite superior na lambda
                        formatted_value = metric_info['formatter'](value)
                    else:
                        formatted_value = metric_info['formatter'](value)

                    table_data.append({
                        "M√©trica": metric_info['label'],
                        "Valor Calculado": formatted_value,
                        "Descri√ß√£o": metric_info['description']
                    })
                except (KeyError, TypeError):
                    # Ignora a m√©trica se o caminho n√£o for encontrado
                    continue
            
            # Filtra entradas duplicadas de intervalos de confian√ßa
            unique_table_data = []
            seen_metrics = set()
            for item in table_data:
                if item['M√©trica'] not in seen_metrics:
                    unique_table_data.append(item)
                    seen_metrics.add(item['M√©trica'])

            # Cria e exibe o DataFrame do pandas
            if unique_table_data:
                df = pd.DataFrame(unique_table_data)
                st.dataframe(
                    df,
                    use_container_width=True,
                    hide_index=True,
                    column_config={
                        "M√©trica": st.column_config.TextColumn("M√©trica", width="medium"),
                        "Valor Calculado": st.column_config.TextColumn("Valor", width="small"),
                        "Descri√ß√£o": st.column_config.TextColumn("Descri√ß√£o", width="large"),
                    }
                )
            else:
                st.warning("N√£o foi poss√≠vel gerar a tabela de resumo de m√©tricas.")
    def render(self):
        self._apply_custom_css()
        if not self.results: # Check if results were properly initialized
            st.error("N√£o foi poss√≠vel gerar o relat√≥rio de resultados. Verifique os dados de entrada.")
            return
            
        st.title("üìä Relat√≥rio de Resultados")
        self._display_main_result()
        st.divider()
        self._display_confidence_intervals()
        self._display_test_validity()
        self._display_temporal_and_planning_analysis()
        self._display_full_results_table()
        st.write("---")